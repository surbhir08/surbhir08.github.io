---
title: FairAgnetBench
abbreviations:
  LLM: Large Language Models
  AI: Artifitial Intelligence
---

(fairnessBench)=
# FairAgnetBench


> Machine Learning for Socio-Technical Systems Lab (ML4STS), University of Rhode Island

## Benchmarking LLM-Agents at Fair Machine Learning

As a machine learning research scholar, I contributed to developing a benchmarking framework for evaluating large language model agents in the context of fairness and reliability. My role involved preparing multi modal datasets, building baseline python  training scripts, developing evaluation scripts to evaluate both model performance and fairness metrics followed by other helper files for agents and contributing to a forthcoming research paper. I have also been involved in designing different research problems for the agents and it's sensitivity analysis.

This experience deepened my understanding of agentic AI systems and the challenges of evaluating fairness and performance in large language models.

Skills: Python, ML/DL liberaries, fair ML concepts, HPC, SLURM, CUDA, AI Systems, Benchmarking, Research
