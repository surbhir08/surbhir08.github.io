## Hi there ðŸ‘‹

You have reached my GitHub page somehow. You're in for a ride ðŸ˜„  
To look at my work in a nicer format, check out [my portfolio](https://github.com/surbhir08/surbhir08.github.io)!


###### Surbhi Rathore
*Cranston, RI*  
`surbhirathore08 [at] gmail.com`  
_[ORCID Profile](https://orcid.org/0009-0007-5045-0623)_  
_[LinkedIn: Surbhi Rathore](https://www.linkedin.com/in/surbhi-rathore-72883344/)_  
_[GitHub: surbhir08](https://github.com/surbhir08)_
_[Google Scholar: surbhi Rathore](https://scholar.google.com/citations?user=yxkrUL4AAAAJ&hl=en)_

:::

###### ðŸ§  About Me

My name is Surbhi Rathore and I am a Phd candidate and research scholar in Computer Science at the University of Rhode Island (expected to graduate in May 2026). My work sits at the intersection of Responsible AI research, trustworthy systems. I am passionate about building tools and frameworks that make research more transparent, reproducible, and accessible to a broader community, and helping others understand the technologies shaping our world. My work bridges technical and empirical methods to address issues of bias, transparency, and accountability in AI. Through my research work, I strive to create more accountable and socially responsible AI systems.


###### ðŸ§© Research Interests

1. Responsible AI research  
2. Benchmarking for fairness and accountability
3. Human-AI collaboration

* Graduate Research Assistant (current) and Teaching Assitant at the University of Rhode Island  
* Current Project and Research:
   * Fair intervention evaluation 
     * simulated datasets that embed statistical biases, allowing practitioners to see how discrimination can propagate through algorithms. By showing these effects in a controlled way, my work guides practitioners in choosing fairness interventions that are most effective at mitigating harm.  
   * FairAgentBench
     * developed a benchmarking framework for evaluating large language model agents in the context of fairness and reliability
* Previous projects:
  * Task fair framework (TFF):
    * Created a quantitative fairness framework based on mutual information to check data bias and could be used in early data preprocessing and model development pipeline.
  * Fair feature selection techniques
  * Human centered study on TFF

* Teaching:
  * Held office hours and working sessions for Data Science class (CSC 310) for four semesters and also took class as an instructor for one semester. 
  * Ran two labs of 30 students each for Database Management systems class for one semesters  
  * Graded and ran lab sessions for software engineering course (CSC 305)
 